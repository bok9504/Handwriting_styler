{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PNG 형식을 pickle 파일로 바꿔주는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 생성을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pickle as pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 이 함수는 각각의 학습이미지를 열어서 검증데이터와 학습데이터로 파일을 나눠주는 코드이다.\n",
    "### from_dir : 학습시킬 데이터의 이미지 경로\n",
    "### train_path : 학습데이터 저장경로\n",
    "### val_path : 검증데이터 저장경로\n",
    "### train_val_split : 검증데이터 비율\n",
    "### with_charid = 뭔지 모르겠으나 True일 경우 label, charid, img_bytes 값을 label, charid 모든경우에 저장\n",
    "###                               False일 경우 label, img_bytes 값을 label 경우에만 저장\n",
    "\n",
    "def pickle_examples(from_dir, train_path, val_path, train_val_split=0.2, with_charid=False):\n",
    "    \"\"\"\n",
    "    Compile a list of examples into pickled format, so during\n",
    "    the training, all io will happen in memory\n",
    "    \"\"\"\n",
    "    \n",
    "    paths = glob.glob(os.path.join(from_dir, \"*.png\"))         ## from_dir 경로에 존재하는 모든 png 파일 입력\n",
    "    with open(train_path, 'wb') as ft:                        ## with as 구문 파일을 자동으로 열고 닫아주는 구문\n",
    "        with open(val_path, 'wb') as fv:\n",
    "            print('all data num:', len(paths))\n",
    "            c = 1\n",
    "            val_count = 0\n",
    "            train_count = 0\n",
    "            if with_charid:\n",
    "                print('pickle with charid')\n",
    "                for p in paths:\n",
    "                    c += 1\n",
    "                    label = int(os.path.basename(p).split(\"_\")[0])  ## 해당 파일을 _ 단위로 나눠서 앞에것을 int형식 저장\n",
    "                    charid = int(os.path.basename(p).split(\"_\")[1].split(\".\")[0])     ## 뒤에것을 확장자 제거하고 저장\n",
    "                    with open(p, 'rb') as f:\n",
    "                        img_bytes = f.read()\n",
    "                        example = (label, charid, img_bytes)\n",
    "                        r = random.random()\n",
    "                        if r < train_val_split:\n",
    "                            pickle.dump(example, fv)\n",
    "                            val_count += 1\n",
    "                            if val_count % 10000 == 0:\n",
    "                                print(\"%d imgs saved in val.obj\" % val_count)\n",
    "                        else:\n",
    "                            pickle.dump(example, ft)\n",
    "                            train_count += 1\n",
    "                            if train_count % 10000 == 0:\n",
    "                                print(\"%d imgs saved in train.obj\" % train_count)\n",
    "                print(\"%d imgs saved in val.obj, end\" % val_count)\n",
    "                print(\"%d imgs saved in train.obj, end\" % train_count)\n",
    "            else:\n",
    "                for p in paths:\n",
    "                    c += 1\n",
    "                    label = int(os.path.basename(p).split(\"_\")[0])\n",
    "                    with open(p, 'rb') as f:\n",
    "                        img_bytes = f.read()\n",
    "                        example = (label, img_bytes)\n",
    "                        r = random.random()\n",
    "                        if r < train_val_split:\n",
    "                            pickle.dump(example, fv)\n",
    "                            val_count += 1\n",
    "                            if val_count % 10000 == 0:\n",
    "                                print(\"%d imgs saved in val.obj\" % val_count)\n",
    "                        else:\n",
    "                            pickle.dump(example, ft)\n",
    "                            train_count += 1\n",
    "                            if train_count % 10000 == 0:\n",
    "                                print(\"%d imgs saved in train.obj\" % train_count)\n",
    "                print(\"%d imgs saved in val.obj, end\" % val_count)\n",
    "                print(\"%d imgs saved in train.obj, end\" % train_count)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 이 함수는 입력한 char_ids와 font_filter와 동일한 데이터를 찾는 경우 save_path에 데이터를 저장해주는 함수이다\n",
    "### from_dir : 학습시킬 데이터의 이미지 경로\n",
    "### save_path : 일치하는 데이터를 저장시킬 경로\n",
    "### char_ids : 데이터가 일치하는지 확인하기 위한 데이터 번호\n",
    "### font_filter : 데이터가 일치하는지 확인하기 위한 데이터 필터\n",
    "\n",
    "def pickle_interpolation_data(from_dir, save_path, char_ids, font_filter):\n",
    "    paths = glob.glob(os.path.join(from_dir, \"*.png\"))         ## from_dir 경로에 존재하는 모든 png 파일 입력\n",
    "    with open(save_path, 'wb') as ft:\n",
    "        c = 0\n",
    "        for p in paths:\n",
    "            charid = int(p.split('/')[-1].split('.')[0].split('_')[1]) ## 해당 파일을 _ 단위로 나눠서 뒤에것을 int형식 저장\n",
    "            label = int(os.path.basename(p).split(\"_\")[0])             ## 앞에것을 확장자 제거하고 저장\n",
    "            if (charid in char_ids) and (label in font_filter): ## char_ids, font_filter에 해당 파일이름이 존재하면 작업수행\n",
    "                c += 1\n",
    "                with open(p, 'rb') as f:\n",
    "                    img_bytes = f.read()\n",
    "                    example = (label, charid, img_bytes)\n",
    "                    pickle.dump(example, ft)\n",
    "        print('data num:', c)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 생성 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_dir = '../get_data/dataset-11172/'\n",
    "train_path = '../get_data/dataset_pkl/train.pickle'\n",
    "val_path = '../get_data/dataset_pkl/val.pickle'\n",
    "save_path = '../get_data/dataset_pkl/data.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data num: 58802\n",
      "10000 imgs saved in train.obj\n",
      "20000 imgs saved in train.obj\n",
      "30000 imgs saved in train.obj\n",
      "10000 imgs saved in val.obj\n",
      "40000 imgs saved in train.obj\n",
      "11856 imgs saved in val.obj, end\n",
      "46946 imgs saved in train.obj, end\n"
     ]
    }
   ],
   "source": [
    "pickle_examples(from_dir, train_path, val_path, train_val_split=0.2, with_charid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data num: 669\n"
     ]
    }
   ],
   "source": [
    "pickle_interpolation_data(from_dir, save_path, list(range(1,35)), list(range(1,3001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
